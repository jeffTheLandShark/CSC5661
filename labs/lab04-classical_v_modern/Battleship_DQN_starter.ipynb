{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f667b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#in this code let's use train an AI to play a game of battleship\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#import useful libraries\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# two classes for these two environments\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "class Battleship:\n",
    "    \"\"\"A class to manage the board\"\"\"\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Set up the constructor\n",
    "        Takes -- config, a dictionary specifying the track dimensions and initial state\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.hit_streak = 0\n",
    "        self.true_state = np.zeros([config[\"n\"], config[\"n\"]], dtype=int)\n",
    "        self.state = np.zeros(\n",
    "            [config[\"n\"], config[\"n\"]], dtype=int\n",
    "        )  # TODO -- consider how to change this\n",
    "        self.old_state = copy.deepcopy(self.state)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def position_maker(self, ship):\n",
    "        \"\"\"A function to choose a position for a ship\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "            ship -- int, the index in the list of ship lengths\n",
    "        Returns:\n",
    "            an int, int pair, the coordinates of the first cell the ship occupies\n",
    "        \"\"\"\n",
    "        coord_1 = np.random.choice(\n",
    "            list(range(self.config[\"n\"] - self.config[\"ships\"][ship] + 1))\n",
    "        )  # choose first coordinate, guaranteed to have ship on board\n",
    "        coord_2 = np.random.choice(\n",
    "            list(range(self.config[\"n\"]))\n",
    "        )  # choose second coordinate\n",
    "        return coord_1, coord_2\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def check_empty(self, coord_1, coord_2, vert, ship):\n",
    "        \"\"\"A function to make sure the proposed location is currently empty\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "            coord_1 -- int, the first coordinate, constrained to ensure the ship lies on the board\n",
    "            coord_2 -- int, the second coordinate\n",
    "            vert -- boolean, whether to orient the ship vertically or horizontally\n",
    "            ship -- int, the index in the list of ship lengths\n",
    "        Returns:\n",
    "            a boolean, indicating if the placement is legal\n",
    "        \"\"\"\n",
    "        if vert:  # if the ship is oriented vertically...\n",
    "            if (\n",
    "                sum(\n",
    "                    self.true_state[\n",
    "                        coord_1 + list(range(self.config[\"ships\"][ship])), coord_2\n",
    "                    ]\n",
    "                )\n",
    "                > 0\n",
    "            ):  # and if there is another ship lying across its path...\n",
    "                empty = False  # set the empty indicator to false\n",
    "            else:  # otherwise if the proposed location is empty...\n",
    "                empty = True  # set the empty indicator to true\n",
    "        else:  # if the ship is oriented horizontally...\n",
    "            if (\n",
    "                sum(\n",
    "                    self.true_state[\n",
    "                        coord_2, coord_1 + list(range(self.config[\"ships\"][ship]))\n",
    "                    ]\n",
    "                )\n",
    "                > 0\n",
    "            ):  # and if there is anther ship lying across its path...\n",
    "                empty = False  # set the empty indicator to false\n",
    "            else:  # otherwise if the proposed location is empty...\n",
    "                empty = True  # set the empty indicator to true\n",
    "        return empty\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def place_ship(self, ship):\n",
    "        \"\"\"A function to put a single ship on the board\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "            ship -- int, the index in the list of ship lengths\n",
    "        \"\"\"\n",
    "        empty = False  # init the stopping criterion\n",
    "        while not empty:  # while we should keep going...\n",
    "            coord_1, coord_2 = self.position_maker(\n",
    "                ship\n",
    "            )  # sample a position for the ship\n",
    "            vert = (\n",
    "                np.random.uniform() < 0.5\n",
    "            )  # choose whether ship is horizontal or vertical\n",
    "            empty = self.check_empty(coord_1, coord_2, vert, ship)  # check if legal\n",
    "        if vert:  # if the ship is vertical...\n",
    "            self.true_state[\n",
    "                coord_1 + list(range(self.config[\"ships\"][ship])), coord_2\n",
    "            ] = 1  # place on board\n",
    "        else:  # if the ship is horizontal...\n",
    "            self.true_state[\n",
    "                coord_2, coord_1 + list(range(self.config[\"ships\"][ship]))\n",
    "            ] = 1  # place on board\n",
    "        vert = (\n",
    "            np.random.uniform() < 0.5\n",
    "        )  # choose whether ship is horizontal or vertical\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def make_board(self):\n",
    "        \"\"\"A function to put all ships on the board\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "        \"\"\"\n",
    "        self.true_state = np.zeros([self.config[\"n\"], self.config[\"n\"]], dtype=int)\n",
    "        for j in range(len(self.config[\"ships\"])):  # loop over ship lengths\n",
    "            self.place_ship(j)  # put on board'\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def reset(self):\n",
    "        \"\"\"A function to reset the board\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "        \"\"\"\n",
    "        self.hit_streak = 0\n",
    "        self.true_state = np.zeros(\n",
    "            [self.config[\"n\"], self.config[\"n\"]], dtype=int\n",
    "        )  # reset the hidden state\n",
    "        self.make_board()  # place ships again\n",
    "        self.state = np.zeros(\n",
    "            [self.config[\"n\"], self.config[\"n\"]], dtype=int\n",
    "        )  # reset the observed state\n",
    "        self.old_state = copy.deepcopy(self.state)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def check_win(self):\n",
    "        \"\"\"A function to check whether the agent has won\n",
    "        Takes:\n",
    "            self -- class instance info above\n",
    "        Returns:\n",
    "            a boolean, indicating if the agent sank all the ships\n",
    "        \"\"\"\n",
    "        if np.sum(self.state > 0) == sum(\n",
    "            self.config[\"ships\"]\n",
    "        ):  # if the number of hits is equal to the total length of ships...\n",
    "            return True  # return true -- the agent won!\n",
    "        else:  # otherwise...\n",
    "            return False  # return false -- the game is still going\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def reward(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function to compute the reward at each step\n",
    "            Takes:\n",
    "                self -- class instance info above\n",
    "            Returns:\n",
    "                r -- float, the reward at this step\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        total_hits = np.sum(self.state == 1)\n",
    "        new_hits = total_hits - np.sum(self.old_state == 1)\n",
    "        weights = [\n",
    "            1,  # reward for a new hit\n",
    "            1.5,  # reward for new hits\n",
    "            2,  # reward for hit streaks\n",
    "        ]\n",
    "        inputs = [total_hits, new_hits, self.hit_streak]\n",
    "        return np.dot(weights, inputs)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def step(self, a):\n",
    "        \"\"\"A function to update the state given the true enemy fleet locations\"\"\"\n",
    "        if (\n",
    "            self.true_state[a[\"row\"], a[\"col\"]] > 0\n",
    "        ):  # if there is a ship at the chosen location...\n",
    "            self.state[a[\"row\"], a[\"col\"]] = (\n",
    "                1  # record a hit on the observed state as a 1\n",
    "            )\n",
    "            self.hit_streak += 1\n",
    "        else:  # if there is no ship\n",
    "            self.state[a[\"row\"], a[\"col\"]] = (\n",
    "                -1\n",
    "            )  # record a miss on the observed state as a -1\n",
    "            self.hit_streak = 0\n",
    "        done = self.check_win()  # check to see if the agent has won\n",
    "        if done:\n",
    "            r = 10  # max(10*np.sum(self.state == 0),10)\n",
    "        else:\n",
    "            r = (\n",
    "                self.reward()\n",
    "            )  # WILL NOT WORK RIGHT NOW -- NEED TO SPECIFIY REWARD FUNCTION\n",
    "        self.old_state = copy.deepcopy(self.state)\n",
    "        return {\"state\": self.state, \"reward\": r, \"done\": done}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#A simple CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Input: (batch_size, 1, 6, 6)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)  # -> (32, 6, 6)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # -> (64, 6, 6)\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=1)  # -> (1, 6, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # (batch_size, 32, 6, 6)\n",
    "        x = F.relu(self.conv2(x))  # (batch_size, 64, 6, 6)\n",
    "        q_map = self.conv3(x)      # (batch_size, 1, 6, 6)\n",
    "        return q_map.squeeze(1)    # -> (batch_size, 6, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d956640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "class Agent:\n",
    "    '''A class to manage the chase'''\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def __init__(self, config):\n",
    "        '''Set up the constructor\n",
    "            Takes -- config, a dictionary specifying the track dimensions and initial state\n",
    "        '''\n",
    "        self.config = config    #save the config file\n",
    "        self.A_s = self.config['A']    #save the action set\n",
    "        #init the deep learning model\n",
    "        #copy the target approximator\n",
    "        #init the replay buffer\n",
    "\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def update_Q_target(self,):\n",
    "        '''A function to update the target approximator\n",
    "        '''\n",
    "        #TODO\n",
    "        \n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def purge_replay_buffer(self,):\n",
    "        '''A function to keep the replay buffer within memory limits\n",
    "        '''\n",
    "        #TODO\n",
    "        \n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def forward_pass(self,):\n",
    "        '''A function to compute the forward pass\n",
    "        '''\n",
    "        #TODO\n",
    "        \n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    \n",
    "    def pi(self,):\n",
    "        '''A function to choose actions using Q-values\n",
    "        '''\n",
    "        #TODO\n",
    "        \n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def make_batch(self):\n",
    "        '''A function to make a batch for updating Q\n",
    "        '''\n",
    "        #TODO\n",
    "\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def update_Q_value(self,):\n",
    "        '''A function to use the batch to estimate the gradient and take a single step\n",
    "        '''\n",
    "        #TODO\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82083429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#Set up the classes -- the environment and the agent\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "env_config = {'n':6,'ships':[2,3,4],'boards':None}    #set up the environmental config\n",
    "\n",
    "A = []    #init the actions\n",
    "for row in range(6):    #loop over vertical velo changes\n",
    "    for col in range(6):    #loop over horizonal velo changes\n",
    "        A.append([row,col])    #record\n",
    "\n",
    "agent_config = {'gamma':0.9    #the discount factor\n",
    "                ,'epsilon':0.1    #the epsilon-greedy parameter\n",
    "                ,'alpha':0.001    #the learning rate\n",
    "                ,'A':A    #the action set\n",
    "                ,'n':6    #the size of the board\n",
    "                ,'M':100000    #set the memory size\n",
    "                ,'B':32    #set the batch size\n",
    "                ,'C':500    #when to update the target approximator\n",
    "                ,'n_steps_for_Q_update':4    #the number of steps to use to update\n",
    "               }   #examples of agent config\n",
    "\n",
    "board = Battleship(env_config)    #set up the environment for testing agent performance\n",
    "agent = Agent(agent_config)    #set up the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca01022-5d58-46ff-98f0-4839d1c8171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@\n",
    "#Training Loop\n",
    "#@@@@@@@@@@@@@\n",
    "N_eps = #TODO\n",
    "for epi in tqdm(range(N_eps)):    #loop over episodes\n",
    "    board.make_board()    #set up the board\n",
    "    done = False    #set the stopping condition\n",
    "    turn = 0    #init the turn count\n",
    "    while not done:#for _ in range(6):    #while the episode goes on...\n",
    "\n",
    "        #TODO\n",
    "        #generate an action\n",
    "        \n",
    "        #init the tuple for this turn\n",
    "        #save the old state\n",
    "        #save the action\n",
    "        #evolve the environment\n",
    "        #save the reward\n",
    "        #save the new state\n",
    "        \n",
    "        #add this tuple to the replay buffer\n",
    "        #remove the oldest tuple if appropriate\n",
    "        \n",
    "        #record whether we've stopped\n",
    "\n",
    "        #update the Q values\n",
    "        #update the target approximator\n",
    "\n",
    "    board.reset()    #reset the board\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84878fcc-4f5a-4728-9698-0168a7e434ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc5661",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
