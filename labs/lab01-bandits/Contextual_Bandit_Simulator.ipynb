{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df307f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contextual_Bandit_generator:\n",
    "\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def __init__(self, config):\n",
    "        self.state = {'X':[],'article':[],'reward':[]}\n",
    "        self.population = [[],[]]\n",
    "        self.population[0], self.population[1] = make_classification(\n",
    "            n_samples=config['n_samples'],\n",
    "            n_features=5,\n",
    "            n_informative=5,\n",
    "            n_classes=5,\n",
    "            n_redundant=0,\n",
    "            n_repeated=0,\n",
    "            flip_y=0.2,\n",
    "            shift = [10,4,0,0,0],\n",
    "            scale = [7,1,1,1,1],\n",
    "            random_state=8\n",
    "        )\n",
    "        self.population[0] = self.feature_engineer(self.population[0])\n",
    "        self.current_context = {'X':[],'best_article':[]}\n",
    "        \n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def feature_engineer(self, Data):\n",
    "        Data[:,0] = (Data[:,0]>0)*1\n",
    "        Data[:,1] = (Data[:,1]>0)*1\n",
    "        Data[:,3][(Data[:,3]<0)] = 0\n",
    "        Data[:,3][(Data[:,3]>5)] = 5\n",
    "        Data[:,3] = np.round(Data[:,3])\n",
    "        Data[:,4] = np.round(Data[:,4])\n",
    "        return Data\n",
    "\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def step(self):\n",
    "        sample = np.random.choice(len(self.population[1]))\n",
    "        x = self.population[0][sample]\n",
    "        ba = self.population[1][sample]\n",
    "        if len(self.state['X']) == 0:\n",
    "            self.state['X'] = x\n",
    "        else:\n",
    "            self.state['X'] = np.vstack((self.state['X'],x))\n",
    "        self.current_context['X'] = x\n",
    "        self.current_context['best_article'] = ba\n",
    "\n",
    "    #@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    def reward(self,a):        \n",
    "        if self.current_context['best_article'] == a:\n",
    "            response = np.random.binomial(n = 1, p = 0.9,size = 1)[0]\n",
    "        else:\n",
    "            response = np.random.binomial(n = 1, p = 0.05,size = 1)[0]\n",
    "        if len(self.state['X']) == 0:      \n",
    "            self.state['article'] = np.array(a)\n",
    "            self.state['reward'] = np.array(response)\n",
    "        else:\n",
    "            self.state['article'] = np.append(self.state['article'],a)\n",
    "            self.state['reward'] = np.append(self.state['reward'],response)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intended setup\n",
    "env_config = {'n_samples':100000}\n",
    "env = Contextual_Bandit_generator(env_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intended use\n",
    "env.step()\n",
    "a = 2\n",
    "env.reward(a)\n",
    "env.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed356f-7928-4bab-9dfb-94427ceb5a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
